{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea75a444",
   "metadata": {},
   "source": [
    "# LangGraph ChatBot 开发指南\n",
    "\n",
    "LangGraph 是一个灵活的 Agent 开发框架，可以帮助您设计复杂的对话工作流和智能代理。\n",
    "\n",
    "本指南将指导您如何使用 LangGraph 构建一个支持**多轮对话的智能客服（聊天机器人）**。\n",
    "\n",
    "我们将从一个基础的聊天机器人开始，逐步添加更多高级功能，并介绍关键的 LangGraph 概念。\n",
    "\n",
    "通过以下几个部分的学习，您将掌握如何逐步构建、增强和管理该聊天机器人。\n",
    "\n",
    "1. **构建Chatbot**： 基于 GPT-4o-mini 构建基础聊天机器人\n",
    "2. **联网查询工具**：为聊天机器人添加工具（结合网络搜索回答问题）\n",
    "3. **增加记忆系统**：在多次调用中保持对话状态\n",
    "4. **人工介入对话**：将复杂查询路由给人工审查或手动更新内容\n",
    "5. **查询历史对话**：通过状态图状态和配置查看/打印历史对话\n",
    "----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ff467-f475-4461-b1c1-3678fbf64298",
   "metadata": {},
   "source": [
    "## LangGraph 核心对象介绍\n",
    "\n",
    "#### **StateGraph 对象**\n",
    "\n",
    "`StateGraph` 是 LangGraph 中的核心概念之一，它定义了聊天机器人或其他任务处理流程的结构。它是一种状态机，通过节点（nodes）和边（edges）来表示系统的状态变化。以下是 `StateGraph` 的关键点：\n",
    "\n",
    "- **定义流程图**：`StateGraph` 是用来创建流程图的对象，图中的每个节点代表一个任务或计算步骤（如调用 LLM、工具或函数），每个边（edge）定义了从一个节点到下一个节点的流向。\n",
    "  \n",
    "- **状态管理**：`StateGraph` 通过状态（`State`）来管理流程中的数据和上下文。每个节点都会接收当前的状态，并且返回一个更新后的状态。这种机制保证了在多轮对话或任务中，机器人能够持续维护上下文信息。\n",
    "\n",
    "- **消息更新**：在 `StateGraph` 中，我们可以定义如何更新状态，例如使用 `add_messages` 函数，表示将消息追加到已有的消息列表，而不是覆盖旧消息。\n",
    "\n",
    "#### StateGraph 的使用步骤\n",
    "1. **定义 State**：首先需要定义状态（`State`），例如用字典来存储消息、工具调用的结果等内容。\n",
    "2. **添加节点**：每个节点表示一个任务单元，可以是任意的 Python 函数。\n",
    "3. **添加边**：通过 `add_edge()` 方法指定节点之间的流向，例如从聊天节点到工具节点，再到结束节点。\n",
    "4. **编译图**：通过 `compile()` 方法将流程图编译为可执行的 `CompiledGraph`。\n",
    "\n",
    "-----------\n",
    "\n",
    "#### **CompiledGraph 对象**\n",
    "\n",
    "`CompiledGraph` 是由 `StateGraph` 编译得到的实际可执行对象。它负责执行在 `StateGraph` 中定义的流程，并处理每个节点的任务。`CompiledGraph` 通过状态的流动来管理整个对话或任务的执行。以下是 `CompiledGraph` 的关键点：\n",
    "\n",
    "- **流程执行**：`CompiledGraph` 是 `StateGraph` 的实际运行版本。当你调用 `stream()` 或 `invoke()` 方法时，它会依次执行图中的节点，并根据每个节点的输出状态决定下一个节点的执行。\n",
    "\n",
    "- **状态检查点（Checkpointing）**：通过使用检查点机制，`CompiledGraph` 可以在每个节点执行完后保存当前的状态，允许任务暂停并在之后恢复。例如，您可以为机器人添加记忆功能或支持“时间旅行”（回到之前的某个状态点）。\n",
    "\n",
    "- **动态路由**：`CompiledGraph` 还支持动态路由（Conditional Edges），允许根据当前状态动态决定下一步执行的节点。这使得机器人可以根据上下文或工具的输出灵活地调整行为。\n",
    "\n",
    "------------\n",
    "\n",
    "#### 关系总结\n",
    "\n",
    "- `StateGraph` 用于定义和构建一个聊天机器人或任务处理流程的结构，通过节点和边来管理流程和状态的流动。\n",
    "- `CompiledGraph` 是 `StateGraph` 编译后的版本，负责实际的流程执行、状态管理和检查点保存。\n",
    "\n",
    "它们结合在一起，提供了一个灵活、可扩展的方式来构建复杂的多步骤对话机器人或任务执行系统。\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa6d74b-5d3c-44c3-b6b6-794f82f366b8",
   "metadata": {},
   "source": [
    "## LangGraph 核心方法介绍\n",
    "\n",
    "`graph.stream` 是 LangGraph 中的一个核心方法，用于执行编译后的状态图（`CompiledGraph`）并以流式（streaming）的方式处理每个节点。通过 `stream` 方法，系统可以逐步执行对话或任务的每个步骤，并在每一步中返回中间结果。这种方式特别适用于长时间任务、逐步处理的工具调用或连续的对话。\n",
    "\n",
    "### `graph.stream` 的核心功能\n",
    "\n",
    "1. **流式执行**：\n",
    "   - `graph.stream` 允许您在每个节点执行时获得结果，类似于生成器的工作方式。在对话或任务流程中，机器人每经过一个节点（如调用工具、获取外部数据、与用户对话），都会返回该节点的执行结果。这使得系统可以逐步处理复杂的任务或多轮对话，而不是一次性等待所有步骤完成。\n",
    "\n",
    "2. **中间状态反馈**：\n",
    "   - 使用 `stream` 方法时，开发者可以在每一步获得当前的中间状态（如对话消息、工具调用的结果）。这对于调试、错误处理和用户实时反馈非常有帮助。\n",
    "   - 比如，在对话中，系统可以在用户输入每一条消息后逐步处理，逐步生成回答，而不是一次性返回最终结果。\n",
    "\n",
    "3. **支持多轮对话**：\n",
    "   - 通过 `stream`，可以让机器人保持对话的状态，使其能够处理复杂的多轮对话。系统在每一步都会保存对话的上下文，并在接收到新消息时恢复对话的状态，继续处理。\n",
    "\n",
    "4. **支持工具调用和多节点执行**：\n",
    "   - `stream` 方法不仅支持对话，还可以用于工具调用等任务。在每个工具节点执行时，系统会返回工具的执行结果，允许您对每个步骤的输出进行检查或处理。\n",
    "   - 它特别适合那些需要多个步骤或节点共同执行的任务，保证每个节点依次运行。\n",
    "\n",
    "---\n",
    "\n",
    "### 典型用法（涵盖1-3部分的重要功能）\n",
    "\n",
    "#### 1. 执行对话\n",
    "\n",
    "```python\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "user_input = \"Hi, can you tell me today's weather?\"\n",
    "\n",
    "# 使用 stream 方法来执行对话\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},  # 传入用户的输入消息\n",
    "    config,  # 对话线程配置，用于标识对话的唯一 ID\n",
    "    stream_mode=\"values\"  # 以流式返回数据\n",
    ")\n",
    "\n",
    "# 遍历每个事件，并输出机器人生成的消息\n",
    "for event in events:\n",
    "    print(event[\"messages\"][-1].content)  # 打印最后一条消息的内容\n",
    "```\n",
    "\n",
    "在这个示例中，`graph.stream` 逐步处理用户的输入，并返回每个步骤的结果。由于使用了 `stream_mode=\"values\"`，系统以流式返回对话的中间结果。\n",
    "\n",
    "#### 2. 执行工具调用\n",
    "\n",
    "```python\n",
    "user_input = \"Please search for the latest news about AI.\"\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# 使用 stream 方法来执行带有工具调用的任务\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},  # 用户输入的消息\n",
    "    config,\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# 遍历事件，获取工具的调用结果\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        # 打印工具的调用结果或机器人回复\n",
    "        print(event[\"messages\"][-1].content)\n",
    "```\n",
    "\n",
    "这个示例展示了如何通过 `graph.stream` 执行包含工具调用的任务。每个工具的调用结果都会在事件中返回，并且可以即时处理和反馈。\n",
    "\n",
    "---\n",
    "\n",
    "### `graph.stream` 的参数\n",
    "\n",
    "- **`inputs`**：输入的字典数据，通常包含对话的消息（如 `{\"messages\": [(\"user\", user_input)]}`），表示用户输入了什么信息。`inputs` 是机器人任务的初始数据。\n",
    "- **`config`**：配置参数，用于指定对话线程 ID、流执行模式等选项。它允许为每个对话或任务指定唯一的标识符，以便系统可以跟踪对话的上下文或任务状态。\n",
    "- **`stream_mode`**：指定返回数据的模式。常见的取值是 `\"values\"`，表示返回处理结果的流式数据。其他模式也可以根据具体需求进行调整。\n",
    "\n",
    "---\n",
    "\n",
    "### 适用场景\n",
    "\n",
    "1. **多轮对话机器人**：在复杂的对话场景中，用户可能与机器人进行多轮对话，并且希望机器人能够持续记住对话上下文。`graph.stream` 允许在每一轮对话中返回中间结果，并保持对话的流畅性和连贯性。\n",
    "  \n",
    "2. **逐步执行复杂任务**：例如，机器人在执行需要多个步骤的任务时，可以通过 `stream` 方法在每个步骤执行完后返回结果，而不是一次性执行整个任务。这种逐步处理的机制可以确保任务的每一步都被正确执行，并且可以随时处理异常情况。\n",
    "\n",
    "3. **实时反馈**：在实时应用中，用户希望能够尽快获得机器人的反馈。通过 `graph.stream`，系统可以在每个步骤中即时返回处理结果，让用户感受到流畅的交互体验。\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "\n",
    "`graph.stream` 是一个强大的工具，用于以流式处理对话和任务的每个步骤。它特别适合那些需要逐步执行和处理的任务场景，如多轮对话、复杂的工具调用或任务处理。通过 `stream`，系统可以在每一步中即时返回结果，并保持任务或对话的上下文信息。\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3f01c-21f0-47be-a32b-3895f46f1b65",
   "metadata": {},
   "source": [
    "## 第 1 部分：构建基础聊天机器人\n",
    "\n",
    "我们将首先使用 LangGraph 创建一个简单的聊天机器人。该机器人将直接响应用户消息。虽然简单，但它将展示 LangGraph 构建的核心概念。在本部分结束时，您将构建一个基础的聊天机器人。\n",
    "\n",
    "### 1. 安装依赖包\n",
    "\n",
    "首先，安装所需的软件包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd46847",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# 安装 LangGraph 和 LangSmith，用于状态图和跟踪\n",
    "%pip install -U langgraph langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb2298",
   "metadata": {},
   "source": [
    "### 2. 设置 LangSmith API 密钥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9db1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 开启 LangSmith 跟踪，便于调试和查看详细执行信息\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ChatBot\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb060c3",
   "metadata": {},
   "source": [
    "### 3. 定义聊天机器人的状态图 `StateGraph`\n",
    "\n",
    "我们将添加节点以表示聊天机器人的逻辑和功能，并添加边来指定如何在功能之间进行转换。\n",
    "\n",
    "#### 代码解析\n",
    "\n",
    "当定义一个状态图时，首先要定义图的状态 `State`。`State` 包含图的状态结构以及 reducer 函数，它们指定如何应用状态更新。\n",
    "\n",
    "在本例中，`State` 是一个带有单一键 `messages` 的 `TypedDict`，该键使用 `add_messages` 函数作为注解，告诉 LangGraph 应该将新消息追加到现有消息列表中，而不是覆盖它。\n",
    "\n",
    "没有注解的状态键将被覆盖，存储最新的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a959d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 定义状态类型，继承自 TypedDict，并使用 add_messages 函数将消息追加到现有列表\n",
    "class State(TypedDict):\n",
    "    # Annotated 源码位于 typing 模块:\n",
    "    # class Annotated:\n",
    "    #     \"\"\"给类型添加运行时注解的特殊类型\n",
    "    #     Annotated[t, ann1, ann2, ...] 是 t 的子类型,同时附加了注解 ann1, ann2, ...\"\"\"\n",
    "    #     def __init__(self, type, *annotations):\n",
    "    #         self.__type = type\n",
    "    #         self.__annotations = annotations\n",
    "    \n",
    "    # add_messages 源码位于 langgraph.graph.message:\n",
    "    # def add_messages(old_value: list, new_value: list) -> list:\n",
    "    #     \"\"\"将新消息追加到现有消息列表中\n",
    "    #     Args:\n",
    "    #         old_value: 现有消息列表 \n",
    "    #         new_value: 要追加的新消息列表\n",
    "    #     Returns:\n",
    "    #         合并后的消息列表\"\"\"\n",
    "    #     return old_value + new_value\n",
    "    \n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 创建一个状态图对象，传入状态定义\n",
    "graph_builder= StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4950d16",
   "metadata": {},
   "source": [
    "现在，状态图知道了两件事：\n",
    "\n",
    "1. 每个我们定义的节点都会接收当前的 `State` 作为输入，并返回一个更新该状态的值。\n",
    "2. `messages` 将追加到当前列表中，而不是直接覆盖。这通过 `Annotated` 语法中的预构建 `add_messages` 函数传达。\n",
    "\n",
    "### 4. 添加聊天节点\n",
    "\n",
    "节点表示一个计算单元。它们通常是常规的 Python 函数。\n",
    "\n",
    "**代码解析：**\n",
    "\n",
    "聊天机器人节点函数（`chatbot`）接收当前的 `State` 作为输入，并返回一个包含更新后的 `messages` 列表的字典。这是所有 LangGraph 节点函数的基础模式。\n",
    "\n",
    "在 `State` 中的 `add_messages` 函数会将 LLM 的响应消息追加到现有的消息列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1607f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10605e560>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 初始化一个 GPT-4o-mini 模型\n",
    "# chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 初始化 ChatOpenAI 模型，指定使用的模型为 'gpt-4o-mini'\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    openai_api_base=\"https://api.gptsapi.net/v1\",\n",
    "    openai_api_key=\"sk-XPp5a40638eec6f1ce1c0333e36bf6305e53c8ea95ccTUXc\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 定义聊天机器人的节点函数，接收当前状态并返回更新的消息列表\n",
    "def chatbot(state: State):\n",
    "    # 这个函数定义类似于 Java 中的:\n",
    "    # public Map<String, List<Message>> chatbot(State state) {\n",
    "    #     return Map.of(\"messages\", Arrays.asList(chatModel.invoke(state.get(\"messages\"))));\n",
    "    # }\n",
    "    \n",
    "    # Python 中的类型提示 state: State 相当于 Java 中的参数类型声明\n",
    "    # 返回的字典相当于 Java 中的 Map\n",
    "    # 列表相当于 Java 中的 List/Array\n",
    "    return {\"messages\":[chat_model.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 第一个参数是唯一的节点名称，第二个参数是每次节点被调用时的函数或对象\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba47db",
   "metadata": {},
   "source": [
    "### 5. 定义聊天机器人对话流程（状态图的起终点）\n",
    "\n",
    "- **起点（START）**：每次运行时，从哪里开始工作。\n",
    "- **终点（END）**：每次运行此节点时，程序可以退出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f06c7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10605e560>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 这类似于 Java 中的:\n",
    "# graph.addEdge(START_NODE, \"chatbot\"); \n",
    "# graph.addEdge(\"chatbot\", END_NODE);\n",
    "# \n",
    "# 其中:\n",
    "# - START 相当于 Java 中的常量 START_NODE\n",
    "# - END 相当于 Java 中的常量 END_NODE\n",
    "# - add_edge() 方法相当于 Java 中的 addEdge() 方法\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f8d09",
   "metadata": {},
   "source": [
    "### 6. 编译图并可视化\n",
    "\n",
    "最后，我们需要能够运行我们的状态图。\n",
    "\n",
    "在图构建器上调用 `compile()`，这会创建一个可执行的 `CompiledGraph`对象。\n",
    "\n",
    "我们可以使用该图(`CompiledGraph`)来调用聊天机器人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff06359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 编译状态图并生成可执行图对象\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# 你可以使用 get_graph 方法来可视化图，并结合 draw 方法（如 draw_ascii 或 draw_png）\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7be101",
   "metadata": {},
   "source": [
    "### 7. 运行图\n",
    "\n",
    "**恭喜！您已经使用 LangGraph 构建了第一个聊天机器人。这个机器人可以通过接受用户输入并生成 LLM 回复来进行基本对话。**\n",
    "\n",
    "现在运行聊天机器人！\n",
    "\n",
    "#### 代码解析\n",
    "\n",
    "1. **聊天循环**：\n",
    "   - `while True:` 启动一个持续的聊天循环，用户可以不断输入问题或命令与聊天机器人互动。\n",
    "\n",
    "2. **获取用户输入**：\n",
    "   - 使用 `input(\"User: \")` 来获取用户的输入消息，并将其赋值给 `user_input` 变量。\n",
    "\n",
    "3. **退出条件**：\n",
    "   - 如果用户输入 `\"quit\"`、`\"exit\"` 或 `\"q\"`，系统会通过 `break` 语句退出聊天循环，结束程序运行。\n",
    "\n",
    "4. **将用户消息传递给聊天机器人**：\n",
    "   - 通过调用 `graph.stream({\"messages\": (\"user\", user_input)})`，将用户的输入传递给聊天机器人模型。`graph.stream` 方法会根据输入的消息生成相应的回复。\n",
    "   - 这里 `\"messages\": (\"user\", user_input)` 表示传递的是用户的输入消息。\n",
    "\n",
    "5. **处理机器人的回复**：\n",
    "   - 遍历 `event.values()` 中的每个值，从机器人生成的回复中提取最后一条消息，并使用 `print(\"Assistant:\", value[\"messages\"][-1].content)` 打印输出聊天机器人的回复内容。\n",
    "\n",
    "该代码是一个简单的聊天机器人框架，用户可以在命令行中输入问题，机器人会根据用户的输入实时生成回复。如果用户输入退出指令，程序会结束对话循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6c741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 你好！有什么我可以帮你的吗？\n",
      "Assistant: LangGraph是一个用于处理和分析自然语言数据的图形模型，旨在将语言中的词汇、句法和语义信息以图的形式表示。LangGraph通常使用图论的方法来捕捉语言元素之间的关系，使得语言处理任务（如文本分类、信息提取、问答系统等）更为高效和准确。\n",
      "\n",
      "在LangGraph中，节点通常代表词、短语或句子，而边则表示它们之间的关系，例如同义词、反义词或依存关系。这种结构使得可以利用图算法（如图遍历、最短路径等）来执行语言处理任务。\n",
      "\n",
      "LangGraph的优势包括：\n",
      "\n",
      "1. **结构化表示**：可以更直观地表示语言中的复杂关系。\n",
      "2. **灵活性**：可以处理不同语言和不同类型的语言任务。\n",
      "3. **信息丰富性**：通过图的拓扑结构，可以捕捉到更多的上下文信息。\n",
      "\n",
      "LangGraph的研究和应用正在不断发展，可能涉及到机器学习、深度学习等技术，以提高自然语言处理系统的整体性能。\n",
      "Assistant: 请提供更多的上下文或者具体信息，这样我才能更好地回答你的问题。例如，你想知道的是哪个人的公司，或者是指哪种产品等。谢谢！\n",
      "Assistant: 抱歉，我无法查看之前的对话记录。请问您想讨论什么？\n",
      "Assistant: 作为一个人工智能，我没有长期记忆。在每一次对话中，我无法记住我们之前的交流内容。每次对话都是独立的。如果你有任何问题或者需要讨论的主题，请随时告诉我！\n",
      "Assistant: 抱歉，我无法查看之前的对话记录。不过，你可以告诉我你想讨论的内容，我会尽力帮助你！\n",
      "Assistant: Hello! How can I assist you today?\n",
      "Assistant: It seems like you may have sent an incomplete message. How can I assist you today? If you have a specific question or topic in mind, let me know!\n"
     ]
    }
   ],
   "source": [
    "# 开始一个简单的聊天循环\n",
    "while True:\n",
    "    # 获取用户输入\n",
    "    # 类似 Java 的 Scanner scanner = new Scanner(System.in)\n",
    "    # scanner.nextLine()\n",
    "    user_input = input(\"User: \")\n",
    "    \n",
    "    # 可以随时通过输入 \"quit\"、\"exit\" 或 \"q\" 退出聊天循环\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")  # 打印告别信息\n",
    "        break  # 结束循环，退出聊天\n",
    "\n",
    "    # 将每次用户输入的内容传递给 graph.stream，用于聊天机器人状态处理\n",
    "    # \"messages\": (\"user\", user_input) 表示传递的消息是用户输入的内容\n",
    "    # 类似 Java 的:\n",
    "    # Stream<Event> events = graph.stream(Map.of(\"messages\", new String[]{\"user\", userInput}));\n",
    "    # events.forEach(event -> { ... });\n",
    "    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n",
    "        \n",
    "        # 遍历每个事件的值\n",
    "        # 遍历事件值集合\n",
    "        # 类似 Java 的:\n",
    "        # for (Map.Entry<String, Object> entry : event.entrySet()) {\n",
    "        #     Object value = entry.getValue();\n",
    "        #     List<Message> messages = (List<Message>) value.get(\"messages\");\n",
    "        #     System.out.println(\"Assistant: \" + messages.get(messages.size()-1).getContent());\n",
    "        # }\n",
    "        for value in event.values():\n",
    "            # 打印输出 chatbot 生成的最新消息\n",
    "            # value[\"messages\"] 是一个消息列表,[-1]获取最后一条消息\n",
    "            # .content 获取消息内容\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497df061",
   "metadata": {},
   "source": [
    "--------------\n",
    "#### 运行结果分析\n",
    "\n",
    "问：详细介绍下 LangGraph 项目\n",
    "\n",
    "gpt-4o-mini 训练数据截止日期，在 LangGraph 项目推出前。\n",
    "\n",
    "因此，直接让模型生成 LangGraph 相关介绍时，会出现事实性的问题。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64039fb",
   "metadata": {},
   "source": [
    "## 第 2 部分：为聊天机器人添加工具\n",
    "\n",
    "为了处理我们聊天机器人无法“记住”回答的问题，我们将集成一个 Web 搜索工具 [Tavily Search](\n",
    "https://python.langchain.com/v0.2/docs/integrations/tools/tavily_search/)。\n",
    "\n",
    "我们的机器人可以使用这个工具找到相关信息，并提供更好的回复。\n",
    "\n",
    "### 1. 安装依赖并设置 Tavily API\n",
    "\n",
    "访问 [Tavily](https://tavily.com/) 官网，注册账号并生成你的 `TAVILY_API_KEY`。\n",
    "\n",
    "Tavily 提供 1000次/月的免费检索额度。\n",
    "\n",
    "在开始之前，确保您已安装 Tavily 搜索引擎所需的包并在环境变量中设置了 `TAVILY_API_KEY`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe20f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# 安装 Tavily 搜索引擎的 Python 包\n",
    "%pip install -U tavily-python\n",
    "%pip install -U langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1758a2-7208-4aa4-8c60-4ec2e57b1783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAVILY_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
    "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")\n",
    "print(\"TAVILY_API_KEY:\", os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448a461",
   "metadata": {},
   "source": [
    "### 2. 定义工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec05131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': \"Beginner's Guide to LangGraph: Understanding State, Nodes, and ...\",\n",
       "  'url': 'https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48',\n",
       "  'content': \"Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 | by Kamal Dhungana | Medium Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 LangGraph — State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI's innovations,Sharing insights for AI community growth Follow\",\n",
       "  'score': 0.74961954},\n",
       " {'title': 'LangGraph Glossary - GitHub Pages',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/',\n",
       "  'content': '[](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-1-19)def node_2(state: OverallState) -> PrivateState: [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-1-25)    return {\"graph_output\": state[\"bar\"] + \" Lance\"} [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-1-31)builder.add_edge(START, \"node_1\") [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-7-13)def my_other_node(state: dict): [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-9-3)graph.add_edge(START, \"node_a\") [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-10-3)graph.add_edge(\"node_a\", END) [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-11-1)graph.add_edge(\"node_a\", \"node_b\") [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-12-1)graph.add_conditional_edges(\"node_a\", routing_function) [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-13-1)graph.add_conditional_edges(\"node_a\", routing_function, {True: \"node_b\", False: \"node_c\"}) [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-14-3)graph.add_edge(START, \"node_a\") [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-15-3)graph.add_conditional_edges(START, routing_function) [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-16-1)graph.add_conditional_edges(START, routing_function, {True: \"node_b\", False: \"node_c\"}) [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-17-4)graph.add_conditional_edges(\"node_a\", continue_to_jokes) [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-20-4)        goto=\"other_subgraph\",  # where `other_subgraph` is a node in the parent graph [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-22-4)graph = StateGraph(State, config_schema=ConfigSchema) [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-24-1)def node_a(state, config): [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-26-3)def human_approval_node(state: State): [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-29-8)    foo: str  # note that this key is shared with the parent graph state [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-29-12)def subgraph_node(state: SubgraphState): [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-29-13)    # note that this subgraph node can communicate with the parent graph via the shared \"foo\" key [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-30-5)    # note that none of these keys are shared with the parent graph state [](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-30-10)def subgraph_node(state: SubgraphState):',\n",
       "  'score': 0.6063825}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# 定义 Tavily 搜索工具，最大搜索结果数设置为 2\n",
    "# 创建 TavilySearchResults 实例\n",
    "# 类似于 Java 中:\n",
    "# TavilySearchResults tool = new TavilySearchResults(2);\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "# 测试工具调用\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba26bd",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "#### 搜索工具结果 如上所示\n",
    "\n",
    "工具返回的是页面摘要，供我们的聊天机器人用于回答问题。\n",
    "\n",
    "### 3. 将工具集成到状态图中\n",
    "\n",
    "以下步骤与第 1 部分类似，只不过我们在 `LLM` 上添加了 `bind_tools`，这使得 LLM 可以在需要时调用搜索工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32631ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11956f6d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 定义状态\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 初始化 LLM 并绑定搜索工具\n",
    "# 初始化 ChatOpenAI 模型，指定使用的模型为 'gpt-4o-mini'\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    openai_api_base=\"https://api.gptsapi.net/v1\",\n",
    "    openai_api_key=\"sk-XPp5a40638eec6f1ce1c0333e36bf6305e53c8ea95ccTUXc\"\n",
    "    )    \n",
    "\n",
    "# 使用 bind_tools 方法将工具绑定到模型\n",
    "llm_with_tools = chat_model.bind_tools(tools)\n",
    "\n",
    "# 更新聊天机器人节点函数，支持工具调用\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 将更新后的节点添加到状态图中\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c99bb",
   "metadata": {},
   "source": [
    "\n",
    "### 4. 处理工具调用\n",
    "\n",
    "我们需要创建一个函数来运行工具。我们通过向图中添加一个新节点来实现这一点。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8e3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# 定义 BasicToolNode，用于执行工具请求\n",
    "class BasicToolNode:\n",
    "    \"\"\"一个在最后一条 AIMessage 中执行工具请求的节点。\n",
    "    \n",
    "    该节点会检查最后一条 AI 消息中的工具调用请求，并依次执行这些工具调用。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        \"\"\"\n",
    "        构造函数,初始化工具映射\n",
    "        @param tools: 工具列表,类似Java中的List<Tool>\n",
    "        @return: None\n",
    "        \"\"\"\n",
    "        # 将工具列表转换为Map结构\n",
    "        # 类似Java中的:\n",
    "        # Map<String, Tool> toolsMap = new HashMap<>();\n",
    "        # for(Tool tool : tools) {\n",
    "        #    toolsMap.put(tool.getName(), tool); \n",
    "        # }\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        \"\"\"执行工具调用\n",
    "        \n",
    "        参数:\n",
    "        inputs: 包含 \"messages\" 键的字典，\"messages\" 是对话消息的列表，\n",
    "                其中最后一条消息可能包含工具调用的请求。\n",
    "        \n",
    "        返回:\n",
    "        包含工具调用结果的消息列表\n",
    "        \"\"\"\n",
    "        # 获取消息列表中的最后一条消息，判断是否包含工具调用请求\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"输入中未找到消息\")\n",
    "\n",
    "        # 用于保存工具调用的结果\n",
    "        outputs = []\n",
    "\n",
    "        # 遍历工具调用请求，执行工具并将结果返回\n",
    "        for tool_call in message.tool_calls:\n",
    "            # 根据工具名称找到相应的工具，并调用工具的 invoke 方法执行工具\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            # 将工具调用结果作为 ToolMessage 保存下来\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),  # 工具调用的结果以 JSON 格式保存\n",
    "                    name=tool_call[\"name\"],  # 工具的名称\n",
    "                    tool_call_id=tool_call[\"id\"],  # 工具调用的唯一标识符\n",
    "                )\n",
    "            )\n",
    "        # 返回包含工具调用结果的消息\n",
    "        return {\"messages\": outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c139e4-af01-4cc8-987e-16b2ec82a662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11956f6d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将 BasicToolNode 添加到状态图中\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833a146",
   "metadata": {},
   "source": [
    "\n",
    "### 5. 添加条件边\n",
    "\n",
    "条件边将控制流从一个节点路由到另一个节点。条件边通常包含 `if` 语句，以根据当前状态将控制流路由到不同的节点。\n",
    "\n",
    "#### 代码解析\n",
    "\n",
    "我们定义一个路由函数 `route_tools`，检查聊天机器人的输出中是否包含工具调用。此函数会在聊天机器人节点完成后检查，决定下一步走向工具节点还是结束对话。\n",
    "\n",
    "1. **`route_tools` 函数**：这是一个路由函数，用来决定机器人在对话流程中的下一步。它会检查状态中的最后一条消息，判断该消息是否包含工具调用请求。\n",
    "   - 如果有工具调用请求（通过 `tool_calls` 属性判断），返回 `\"tools\"`，表示需要执行工具节点。\n",
    "   - 如果没有工具调用请求，则返回 `\"__end__\"`，表示对话流程结束。\n",
    "\n",
    "2. **`add_conditional_edges`**：这是 LangGraph 中用于条件路由的函数。它允许我们根据 `route_tools` 函数的返回值决定下一个要执行的节点。比如：\n",
    "   - 如果返回值是 `\"tools\"`，则执行工具节点。\n",
    "   - 如果返回值是 `\"__end__\"`，则结束流程。\n",
    "\n",
    "3. **`add_edge`**：当工具节点执行完成后，机器人会返回到 `chatbot` 节点继续对话。\n",
    "\n",
    "4. **编译状态图**：最后，使用 `graph_builder.compile()` 编译状态图，生成一个 `CompiledGraph`，这个对象可以实际执行对话流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fafcaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "# 定义路由函数，检查工具调用\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    使用条件边来检查最后一条消息中是否有工具调用。\n",
    "    \n",
    "    参数:\n",
    "    state: 状态字典或消息列表，用于存储当前对话的状态和消息。\n",
    "    \n",
    "    返回:\n",
    "    如果最后一条消息包含工具调用，返回 \"tools\" 节点，表示需要执行工具调用；\n",
    "    否则返回 \"__end__\"，表示直接结束流程。\n",
    "    \"\"\"\n",
    "    # 检查状态是否是列表类型（即消息列表），取最后一条 AI 消息\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    # 否则从状态字典中获取 \"messages\" 键，取最后一条消息\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    # 如果没有找到消息，则抛出异常\n",
    "    else:\n",
    "        raise ValueError(f\"输入状态中未找到消息: {state}\")\n",
    "\n",
    "    # 检查最后一条消息是否有工具调用请求\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"  # 如果有工具调用请求，返回 \"tools\" 节点\n",
    "    return \"__end__\"  # 否则返回 \"__end__\"，流程结束\n",
    "\n",
    "# 添加条件边，判断是否需要调用工具\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",  # 从聊天机器人节点开始\n",
    "    route_tools,  # 路由函数，决定下一个节点\n",
    "    {\n",
    "        \"tools\": \"tools\", \n",
    "        \"__end__\": \"__end__\"\n",
    "    },  # 定义条件的输出，工具调用走 \"tools\"，否则走 \"__end__\"\n",
    ")\n",
    "\n",
    "# 当工具调用完成后，返回到聊天机器人节点以继续对话\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# 指定从 START 节点开始，进入聊天机器人节点\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bdf00b",
   "metadata": {},
   "source": [
    "\n",
    "### 6. 编译图并可视化\n",
    "\n",
    "使用以下代码可视化构建的状态图：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ca50a69-6dcc-4b6d-b9d7-3afedf260d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译状态图，生成可执行的流程图\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6206f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f90b11",
   "metadata": {},
   "source": [
    "### 7. 运行图\n",
    "\n",
    "现在，我们可以询问机器人超出其训练数据范围的问题。\n",
    "\n",
    "#### 代码解析\n",
    "\n",
    "1. **`while True` 循环**：\n",
    "   - 这是一个无限循环，用于保持对话的持续进行，直到用户输入退出命令为止。每次用户输入一条消息，系统都会将消息传递给机器人进行处理。\n",
    "\n",
    "2. **用户输入**：\n",
    "   - `input(\"User: \")` 用于从用户处获取输入信息，模拟与机器人对话的场景。\n",
    "   - 如果用户输入的是 `\"quit\"`、`\"exit\"` 或 `\"q\"`，系统将打印 `\"Goodbye!\"` 并退出循环，结束程序。\n",
    "\n",
    "3. **`graph.stream`**：\n",
    "   - `graph.stream({\"messages\": [(\"user\", user_input)]})` 会将用户的输入消息传递给状态图（graph）进行处理，`graph` 会根据流程生成相应的回复。\n",
    "   - `\"messages\": [(\"user\", user_input)]`：这是传递给机器人对话系统的输入消息，表示来自用户的输入内容。\n",
    "\n",
    "4. **遍历 `event.values()`**：\n",
    "   - `graph.stream` 会生成一系列的 `event`，每个 `event` 都包含机器人的响应消息。通过遍历 `event.values()`，我们可以获取每个消息的内容。\n",
    "   - 如果最后一条消息是 `BaseMessage` 类型（机器人回复），则通过 `print(\"Assistant:\", value[\"messages\"][-1].content)` 将机器人的回复输出到控制台。\n",
    "\n",
    "5. **`BaseMessage`**：\n",
    "   - `BaseMessage` 是 LangChain 中的消息类型，用于表示机器人和用户之间的消息。在这里，它用于确认从机器人生成的消息是否符合标准格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# 进入一个无限循环，用于模拟持续的对话\n",
    "while True:\n",
    "    # 获取用户输入\n",
    "    user_input = input(\"User: \")\n",
    "    \n",
    "    # 如果用户输入 \"quit\"、\"exit\" 或 \"q\"，则退出循环，结束对话\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")  # 打印告别语\n",
    "        break  # 退出循环\n",
    "\n",
    "    # 使用 graph.stream 处理用户输入，并生成机器人的回复\n",
    "    # \"messages\" 列表中包含用户的输入，传递给对话系统\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        \n",
    "        # 遍历 event 的所有值，检查是否是 BaseMessage 类型的消息\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                # 如果消息是 BaseMessage 类型，则打印机器人的回复\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02dd51-1a42-4b00-bc45-4fb619f55ad0",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f64614",
   "metadata": {},
   "source": [
    "\n",
    "## 搜索引擎工具赋能前后对比\n",
    "\n",
    "下面对比使用 搜索引擎工具前后，chatbot 生成结果对比\n",
    "\n",
    "\n",
    "### 用户问题\n",
    "\n",
    "```shell\n",
    "User:  详细介绍下 LangGraph 项目\n",
    "```\n",
    "\n",
    "### ChatBot + Web Search Tool（整合搜索结果后生成正确回答）\n",
    "\n",
    "```\n",
    "Assistant: LangGraph 是一个用于构建具有状态的、多参与者应用程序的库，特别是与大型语言模型（LLMs）结合使用。它主要用于创建代理和多代理工作流。与其他 LLM 框架相比，LangGraph 提供了一些核心优势，包括循环、可控性和持久性。\n",
    "\n",
    "### 主要特点\n",
    "1. **循环**：LangGraph 允许定义涉及循环的流程，这对大多数代理架构至关重要。\n",
    "2. **可控性**：用户可以更好地控制工作流的执行。\n",
    "3. **持久性**：能够保存状态，使得应用程序能够在不同的会话中保持一致性。\n",
    "\n",
    "LangGraph 的设计使其能够处理复杂的多代理环境，支持用户定义和管理参与者之间的交互。它基于有向无环图（DAG）的解决方案，使得构建和维护复杂工作流变得更加高效。\n",
    "\n",
    "### 资源链接\n",
    "- [LangGraph GitHub](https://github.com/langchain-ai/langgraph)\n",
    "- [LangGraph 官方文档](https://github.langchain.ac.cn/langgraph/)\n",
    "```\n",
    "\n",
    "### ChatBot-only（模型自己编造的 LangGraph 项目描述）\n",
    "\n",
    "```\n",
    "Assistant: LangGraph 是一个旨在推动自然语言处理（NLP）和图形结构数据结合的项目。它通常涉及将语言模型与图形数据结构相结合，以便更有效地处理和理解复杂的关系和语义信息。以下是 LangGraph 项目的一些关键要素：\n",
    "\n",
    "1. **目标与愿景**：\n",
    "   LangGraph 的主要目标是通过将语言理解与图形表示结合起来，增强机器对人类语言的理解能力。这种结合可以使机器更好地处理信息，识别和推理出不同实体之间的关系。\n",
    "\n",
    "2. **图形结构**：\n",
    "   在 LangGraph 中，图形结构通常用于表示实体及其之间的关系。这种结构可以是知识图谱、社交网络图或其他形式的图形数据，能够捕捉到丰富的语义信息。\n",
    "\n",
    "3. **语言模型**：\n",
    "   LangGraph 通常与先进的语言模型（如 BERT、GPT 等）集成，这些模型能够处理和生成自然语言文本。通过将语言模型与图形结构结合，LangGraph 可以在回答问题、信息检索和对话系统等任务中表现得更为出色。\n",
    "\n",
    "4. **应用场景**：\n",
    "   LangGraph 可以应用于多个领域，包括：\n",
    "   - **信息检索**：通过图谱增强搜索引擎的理解能力，提高检索结果的相关性。\n",
    "   - **对话系统**：改善虚拟助手和聊天机器人的对话能力，使其能够进行更自然和智能的交互。\n",
    "   - **知识管理**：在企业和组织中，通过图形结构更好地组织和管理知识。\n",
    "\n",
    "5. **研究与发展**：\n",
    "   LangGraph 还可能涉及大量的研究工作，包括图神经网络（GNN）、知识图谱的构建和更新、以及如何更好地将语言模型与图形数据结合的方法。\n",
    "\n",
    "6. **开源与社区**：\n",
    "   LangGraph 项目通常鼓励开源和社区参与，以促进技术的快速发展和应用。开发者和研究人员可以贡献代码、文档和其他资源，推动项目的进步。\n",
    "\n",
    "总之，LangGraph 是一个前沿项目，旨在通过将语言处理与图形数据结合，提升机器对自然语言的理解和处理能力。这一领域的发展将对人工智能和数据科学产生深远的影响。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fbba90-b3d2-4614-99f8-adad9b7e6c0f",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "# Homework: \n",
    "\n",
    "1. 运行和测试第1部分的聊天机器人（ChatBot-Only），并尝试找到一个其无法回答正确的事实性问题。\n",
    "1. 使用联网查询工具（如：Tavily），在第2部分的聊天机器人（ChatBot + Tool）上测试相同问题，并对比生成结果。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e91d18-e480-41ea-95d2-e4f34f419d14",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82108f5",
   "metadata": {},
   "source": [
    "## 第 3 部分：为聊天机器人添加记忆功能\n",
    "\n",
    "目前机器人可以使用工具来回答问题，但它还无法记住之前的对话内容。为了解决这个问题，我们将为机器人添加记忆功能，让它能够维护对话状态并实现多轮对话。\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230fe85",
   "metadata": {},
   "source": [
    "`MemorySaver` 是 LangGraph 中的一个检查点机制（checkpointing），用于保存和恢复对话或任务执行的状态。通过 `MemorySaver`，我们可以在每个步骤后保存机器人的状态，并在之后恢复对话，允许机器人具有“记忆”功能，支持多轮对话、错误恢复、时间旅行等功能。\n",
    "\n",
    "### `MemorySaver` 的核心功能\n",
    "\n",
    "1. **状态持久化**：\n",
    "   - `MemorySaver` 以内存的形式保存对话或任务的当前状态。在每次状态图（StateGraph）执行时，`MemorySaver` 会记录执行到某个节点的状态，并将状态保存在内存中。\n",
    "   - 在实际应用中，可以替换成 `SqliteSaver` 或 `PostgresSaver`，将状态保存到数据库中，以便在系统重新启动后仍能恢复之前的对话。\n",
    "   - 参考文档：https://langchain-ai.github.io/langgraph/how-tos/persistence/\n",
    "\n",
    "2. **多轮对话支持**：\n",
    "   - 使用 `MemorySaver`，每次调用状态图时，都会将对话的上下文保存下来。当用户重新发送消息时，机器人可以加载先前的状态，继续进行对话，而不会丢失上下文。\n",
    "   - 例如，用户可以在多轮对话中提到之前的内容，机器人能够记住这些信息并做出相应的反应。\n",
    "\n",
    "3. **错误恢复**：\n",
    "   - 在任务执行过程中，如果发生了错误，`MemorySaver` 可以帮助机器人恢复到之前的状态，从而重试任务或采取其他措施来处理错误。\n",
    "   - 它可以让机器人在任务失败或异常时从上一次成功的状态继续执行，而无需从头开始。\n",
    "\n",
    "4. **时间旅行**：\n",
    "   - `MemorySaver` 还支持时间旅行功能。开发者可以回溯到之前的某个对话状态，从那个时间点继续执行不同的分支，这在调试和交互式应用中非常有用。\n",
    "   - 用户或开发者可以选择从某个保存的状态点重新开始，并探索不同的执行路径。\n",
    "\n",
    "### 使用场景\n",
    "\n",
    "- **对话系统**：当用户和机器人之间进行多轮对话时，机器人需要记住之前的消息和上下文，以便提供连续性的回复。`MemorySaver` 能帮助机器人保存对话的状态，并在下次调用时恢复先前的对话。\n",
    "  \n",
    "- **任务执行系统**：在复杂任务执行流程中，如果发生中断或错误，`MemorySaver` 能帮助系统从最近的检查点恢复，继续完成未完成的任务。\n",
    "\n",
    "- **调试与实验**：开发者可以通过保存多个状态检查点，回溯到不同的状态节点，进行调试或探索不同的对话分支和执行路径。\n",
    "\n",
    "### 代码示例\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 创建内存检查点\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 在编译图时，将 MemorySaver 作为检查点传递\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# 执行状态图，保存当前对话的状态\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream({\"messages\": [(\"user\", \"Hi, what's the weather today?\")]}, config)\n",
    "\n",
    "# 在下次调用时，从内存检查点恢复对话状态\n",
    "events = graph.stream({\"messages\": [(\"user\", \"Can you tell me tomorrow's weather too?\")]}, config)\n",
    "```\n",
    "\n",
    "### 总结\n",
    "\n",
    "`MemorySaver` 是 LangGraph 中用于在内存中保存对话状态的机制，支持机器人的多轮对话、状态恢复和时间旅行等功能。它通过检查点机制，使机器人可以在任务或对话的不同阶段保存并恢复状态，从而提高对话系统的连续性和容错能力。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2918a620",
   "metadata": {},
   "source": [
    "### 1. 创建 MemorySaver 检查点\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1093d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 创建内存检查点\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ecf8c",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e277e",
   "metadata": {},
   "source": [
    "### 2. 使用检查点编译图\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436f151",
   "metadata": {},
   "source": [
    "在编译图时，我们将提供检查点功能，机器人可以在每个步骤中保存状态。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaf106fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da903750-f00b-4208-8bb4-460a768843c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b3e5a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04a076a",
   "metadata": {},
   "source": [
    "### 3. 执行聊天机器人\n",
    "\n",
    "我们仍然按照之前的方式执行机器人，只是这次它会在每一步保存对话状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb3dfde",
   "metadata": {},
   "source": [
    "\n",
    "#### 代码解析\n",
    "\n",
    "1. **config 配置**：\n",
    "   - `config` 是一个包含对话线程信息的字典，用于指定本次对话的唯一线程 ID。在这个例子中，`thread_id` 被设置为 `\"1\"`，这意味着该对话会与该线程关联。\n",
    "   - 每个线程 ID 代表一个独立的对话流，使用 `MemorySaver` 时，机器人可以在同一个 `thread_id` 下记住对话的上下文。\n",
    "\n",
    "2. **用户输入消息**：\n",
    "   - `user_input` 表示用户的输入消息，在这里用户输入了 `\"Hi there! My name is Peng.\"`。这个消息将作为对话的起始消息传递给机器人。\n",
    "\n",
    "3. **graph.stream**：\n",
    "   - `graph.stream` 是用于执行状态图的函数。它会根据传入的消息和配置执行对话流程。\n",
    "   - `{\"messages\": [(\"user\", user_input)]}`：第一个参数包含用户的输入消息。消息格式是一个元组，`(\"user\", user_input)` 表示这是来自用户的消息。\n",
    "   - `config`：第二个参数指定对话的线程配置，这里使用 `{\"configurable\": {\"thread_id\": \"1\"}}`，表示这次对话属于线程 ID 为 `1` 的对话流。\n",
    "   - `stream_mode=\"values\"`：设置流模式为 `\"values\"`，表示返回消息中的内容数据。\n",
    "\n",
    "4. **遍历事件并打印消息**：\n",
    "   - `for event in events` 遍历每个从 `graph.stream` 中返回的事件，`event[\"messages\"][-1]` 获取每个事件中的最后一条消息。\n",
    "   - `pretty_print()`：调用消息对象的 `pretty_print()` 方法来格式化并打印消息的内容。这通常用于输出对话中的 AI 响应或工具调用结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# 用户输入的消息\n",
    "user_input = \"Hi there! My name is Peng.\"\n",
    "\n",
    "# 第二个参数 config 用于设置对话线程 ID\n",
    "# 在这里，\"thread_id\" 是唯一标识符，用于保存和区分对话线程。\n",
    "# 每个对话线程的状态将由 MemorySaver 保存下来，因此可以跨多轮对话继续进行。\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},  # 第一个参数传入用户的输入消息，消息格式为 (\"user\", \"输入内容\")\n",
    "    config,  # 第二个参数用于指定线程配置，包含线程 ID\n",
    "    stream_mode=\"values\"  # stream_mode 设置为 \"values\"，表示返回流式数据的值\n",
    ")\n",
    "\n",
    "# 遍历每个事件，并打印最后一条消息的内容\n",
    "for event in events:\n",
    "    # 通过 pretty_print 打印最后一条消息的内容\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24b166",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a5dee8",
   "metadata": {},
   "source": [
    "在下次执行时，机器人将记住之前的对话内容：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Remember my name?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    config,\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a52aae",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f7e73",
   "metadata": {},
   "source": [
    "通过这两步操作，您已经成功为机器人添加了对话记忆功能，它可以记住之前的交互，并在后续的对话中做出相应的回应。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8df867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 机器人仅记住同一个线程中的历史对话，尝试切换到线程2\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90b143",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023df43",
   "metadata": {},
   "source": [
    "检查点让机器人可以记住对话状态，您可以通过 `get_state` 函数查看机器人当前的状态：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33358b-945d-419e-acaa-11cb5eaccdd9",
   "metadata": {},
   "source": [
    "### 使用 Pandas 表格呈现状态\n",
    "\n",
    "对于其中的 messages 等结构化数据，可以将其转换为 Pandas DataFrame 进行展示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e6291-acef-44f5-97f6-fd542d16cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 将消息内容转换为 DataFrame 显示\n",
    "messages = snapshot.values['messages']\n",
    "df = pd.DataFrame([{\n",
    "    'content': msg.content,\n",
    "    'message_id': msg.id,\n",
    "    'type': type(msg).__name__,\n",
    "    'token_usage': msg.response_metadata.get('token_usage') if hasattr(msg, 'response_metadata') else None\n",
    "} for msg in messages])\n",
    "\n",
    "df  # Jupyter 会自动渲染 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2128bcb",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c557f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15417aa1",
   "metadata": {},
   "source": [
    "## 第 4 部分：引入人类审查\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55389548",
   "metadata": {},
   "source": [
    "有时机器人可能需要人类的介入来做出复杂决策，或者某些任务需要人类批准。LangGraph 支持这种“人类参与”的工作流，您可以在对话中加入人类审查。\n",
    "\n",
    "第4部分，主要展示了如何通过 LangGraph 进行多轮对话和工具调用，并且能够手动更新对话状态、插入工具调用的结果，之后继续执行对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21516923",
   "metadata": {},
   "source": [
    "### 1. 编译图时添加中断\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22974e2c",
   "metadata": {},
   "source": [
    "我们可以通过 `interrupt_before` 参数，在工具节点执行之前中断对话，让人类有机会审查。\n",
    "\n",
    "\n",
    "**编译状态图**：\n",
    "   - `graph_builder.compile()` 用于编译状态图，生成可执行的 `CompiledGraph` 对象。\n",
    "   - `checkpointer=memory` 使用内存作为检查点保存对话状态。\n",
    "   - `interrupt_before=[\"tools\"]` 表示在执行 \"tools\" 节点之前中断，允许手动干预。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a9dc7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译状态图，指定在工具节点之前进行中断\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,  # 使用 MemorySaver 作为检查点系统\n",
    "    interrupt_before=[\"tools\"],  # 在进入 \"tools\" 节点前进行中断\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4a8ca-67cc-44a5-8ee3-3bb4167ae07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a29fe2",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93cf40",
   "metadata": {},
   "source": [
    "### 2. 执行对话并在工具调用前中断\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c06a58",
   "metadata": {},
   "source": [
    "我们现在来执行对话，并在工具节点之前进行中断，以便人类介入。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bc5112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户输入的消息\n",
    "user_input = \"我正在学习LangGraph。你能帮我做一些研究吗？\"\n",
    "# 配置新的对话线程 ID，用于保存和恢复对话状态\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# 使用 stream 方法处理用户输入并返回事件\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    config,\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# 遍历每个事件并输出最后一条消息的内容\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()  # 打印消息内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea1621",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7db0f",
   "metadata": {},
   "source": [
    "检查图的状态，确认已经中断。\n",
    "\n",
    "**获取状态快照**：\n",
    "   - 使用 `graph.get_state(config)` 获取当前对话的状态快照。\n",
    "   - `snapshot.next` 显示下一个将要执行的节点（在中断时为 \"tools\" 节点）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前对话的状态快照\n",
    "snapshot = graph.get_state(config)\n",
    "# 查看快照中下一个要执行的节点\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e17fc-9ebb-407c-8d8b-40c4dbb7f654",
   "metadata": {},
   "source": [
    "请注意，与上次不同，“下一个”节点被设置为'tools'。我们在这里中断了！让我们检查一下工具调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568e527-28b7-412f-8a48-d22e4ad55d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95436842-b3fa-4e0e-80f9-eed3aaa8f709",
   "metadata": {},
   "source": [
    "这个查询看起来很合理。这里没有需要过滤的内容。人类能做的最简单的事情就是让图形继续执行。我们在下面这样做。\n",
    "\n",
    "**接下来，继续执行图！**\n",
    "\n",
    "传入 `None` 便是让图从它停止的地方继续，而不会向状态中添加任何新内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1c0708-cbf9-4040-8365-f2c162468689",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4ea6f-15cf-44b8-a47f-3c69a7943ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "347b87fc",
   "metadata": {},
   "source": [
    "### 3. 人工介入，修改工具执行结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7365a2b7",
   "metadata": {},
   "source": [
    "我们直接使用人工定义的内容，作为工具的返回结果。\n",
    "\n",
    "**手动插入工具调用结果**：\n",
    "   - 创建一个 `ToolMessage` 消息对象，内容是手动提供的工具调用结果，如 `\"LangGraph 是一个用于构建状态化、多参与者应用的库\"`。\n",
    "   - `tool_call_id` 使用之前的工具调用 ID 来关联这个工具调用消息。\n",
    "\n",
    "**更新状态**：\n",
    "   - 通过 `graph.update_state(config, {\"messages\": [tool_message]})` 手动更新对话状态，插入新的工具调用结果。\n",
    "\n",
    "**继续执行对话**：\n",
    "   - 使用 `graph.stream(None, config)` 继续执行对话，处理工具调用后的节点。\n",
    "   - 打印后续生成的消息，显示机器人对工具调用结果的响应。\n",
    "\n",
    "**工具调用最终输出是人工手动输入的内容**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动生成一个工具调用的消息，并更新到对话状态中\n",
    "tool_message = ToolMessage(\n",
    "    content=\"LangGraph 是一个用于构建状态化、多参与者应用的库。\",  # 工具调用返回的内容\n",
    "    tool_call_id=snapshot.values[\"messages\"][-1].tool_calls[0][\"id\"]  # 关联工具调用的 ID\n",
    ")\n",
    "\n",
    "# 更新对话状态，加入工具调用的结果\n",
    "graph.update_state(config, {\"messages\": [tool_message]})\n",
    "\n",
    "# 继续执行对话，查看工具调用后的后续处理\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()  # 打印后续生成的消息内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdf42b",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## 第5部分： 查看 ChatBot 历史对话\n",
    "\n",
    "在 LangGraph 中，可以使用 `graph.get_state_history()` 来获取对话的所有历史状态。\n",
    "\n",
    "传入参数：`{\"configurable\": {\"thread_id\": \"1\"}}`，可以获取指定线程的对话状态。\n",
    "\n",
    "```python\n",
    "# 获取指定线程 ID 的所有历史状态\n",
    "history = graph.get_state_history({\"configurable\": {\"thread_id\": \"1\"}})\n",
    "\n",
    "# 遍历历史记录，打印每个状态中的所有消息\n",
    "for state in history:\n",
    "    print(\"=== 对话历史 ===\")\n",
    "    # 遍历每个状态中的消息记录\n",
    "    for message in state.values[\"messages\"]:\n",
    "        if isinstance(message, BaseMessage):\n",
    "            # 根据消息类型区分用户与机器人\n",
    "            if \"user\" in message.content.lower():\n",
    "                print(f\"User: {message.content}\")\n",
    "            else:\n",
    "                print(f\"Assistant: {message.content}\")\n",
    "```\n",
    "\n",
    "\n",
    "### **为什么不用 events 获取历史？**\n",
    "\n",
    "如果您使用 events，每次调用 graph.stream() 时，您只能获取当前的对话步骤，而不是之前的对话记录。要保留对话历史，您需要在每次获取 events 时将结果手动保存，这样会增加复杂度。\n",
    "\n",
    "\n",
    "### 对话历史去重\n",
    "\n",
    "直接运行上面的代码，可能会出现重复的对话历史。\n",
    "\n",
    "- **问题来源**：重复的状态快照和无消息的中间状态导致了多次重复的对话历史和空对话历史。\n",
    "\n",
    "为了处理这些问题，我们可以引入更严格的过滤条件，并确保只打印那些包含**新消息**或有效消息的状态。\n",
    "\n",
    "- **解决方案**：通过检查消息类型和 ID 来过滤无效和重复的消息，并只输出真正包含对话内容的状态快照。\n",
    "\n",
    "### 代码解析\n",
    "\n",
    "1. **`valid_messages` 列表**：这段代码检查每条消息是否是 `BaseMessage` 类型，同时确保该消息之前没有被处理过。如果消息符合这些条件，则被视为有效消息。\n",
    "\n",
    "2. **输出条件**：只有当存在有效消息时，才打印 `=== 对话历史 ===`，否则打印 `=== 空对话历史（无有效消息） ===`。\n",
    "\n",
    "3. **避免重复输出**：通过 `seen_message_ids` 集合来存储已经处理过的消息 ID，确保每条消息只被打印一次，防止重复输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2fe74-4dd8-4cd8-9b30-2a34efaf53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取指定线程 ID 的所有历史状态\n",
    "history = graph.get_state_history({\"configurable\": {\"thread_id\": \"3\"}})\n",
    "\n",
    "# 使用集合存储已处理过的消息 ID\n",
    "seen_message_ids = set()\n",
    "\n",
    "# 遍历历史记录，打印每个状态中的所有消息\n",
    "for state in history:\n",
    "    # 获取状态中的消息列表\n",
    "    messages = state.values.get(\"messages\", [])\n",
    "    \n",
    "    # 检查是否存在至少一条未处理的 BaseMessage 类型的消息\n",
    "    valid_messages = [msg for msg in messages if isinstance(msg, BaseMessage) and msg.id not in seen_message_ids]\n",
    "    \n",
    "    if valid_messages:\n",
    "        print(\"=== 对话历史 ===\")\n",
    "        for message in valid_messages:\n",
    "            seen_message_ids.add(message.id)  # 记录消息 ID，避免重复处理\n",
    "            if \"user\" in message.content.lower():\n",
    "                print(f\"User: {message.content}\")\n",
    "            else:\n",
    "                print(f\"Assistant: {message.content}\")\n",
    "    else:\n",
    "        print(\"=== 空对话历史（无有效消息） ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43681f46-8d20-4002-92c3-f121cd52a8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778ec5f-13e3-40f9-b17b-769e87e8980e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82f58d4f-87a7-4d5d-b962-553b66407812",
   "metadata": {},
   "source": [
    "# Homework: \n",
    "\n",
    "1. 运行和测试第1部分的聊天机器人（ChatBot-Only），并尝试找到一个其无法回答正确的事实性问题。\n",
    "1. 使用联网查询工具（如：Tavily），在第2部分的聊天机器人（ChatBot + Tool）上测试相同问题，并对比生成结果。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0696cb2-16f9-4db0-a395-18e6246cea95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jike4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
